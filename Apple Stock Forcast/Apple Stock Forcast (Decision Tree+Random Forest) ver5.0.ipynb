{"cells":[{"cell_type":"code","source":["#Version 5.0\n#Decision Tree and Random Forest\nfrom pyspark.sql import SQLContext, Window\nfrom pyspark.sql.functions import *\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor, LinearRegression\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.sql.functions import abs, sqrt\nfrom pyspark.sql import SparkSession\nfrom pyspark import SparkContext\n\ndef sMAPE(df, prediction = \"prediction\", label = \"label\"):\n    '''\n    The function that calculates sMape between prediction and label.\n\n    Args:\n        df (dataframe): The dataframe which contains the prediction and label.\n        prediction (str): The prediction column's name in strings.\n        label (str): The label column's name in strings.\n\n    Returns:\n        sMAPE (float): Returns sMAPE value (%) in float.\n    '''\n    from  pyspark.sql.functions import abs\n    df = df.select(prediction,label)\n    df = df.withColumn('abs_diff',abs(df[prediction] - df[label]))\\\n           .withColumn('abs_prediction',abs(df[prediction]))\\\n           .withColumn('abs_label',abs(df[label]))\n    df = df.withColumn('pre-sum_smape',df['abs_diff']/((df['abs_prediction']+df['abs_label'])/2))\n    sum_smape = df.agg({'pre-sum_smape':'sum'}).collect()[0][0]\n    sMAPE = 100*sum_smape/df.count()\n    return sMAPE\n\ndef add_feature(df, new_df_name, colname, rename):\n    '''\n    The function adds a new feature column to a df.\n\n    Args:\n        df (dataframe): The original dataframe.\n        new_df_name (str): The name of the new df.\n        colname (str): The new feature col's name in the new df.\n        rename (str): What you want the name to be after it is added to your original df.\n\n    Returns:\n        df (dataframe): Returns df with 1 additional col.\n    '''\n    from pyspark.sql import SQLContext\n    new = sqlContext.sql('SELECT * FROM {0}'.format(new_df_name)).dropna()\n    new = new.select(\"Date\",\"{0}\".format(colname))\n    new = new.withColumnRenamed(\"{0}\".format(colname),\"{0}\".format(rename)).withColumnRenamed(\"Date\",\"new_Date\")\n    df = df.join(new,df[\"Date\"] == new[\"new_Date\"]).drop(\"new_Date\")\n    \n    return df\n  \ndef target_creation(df, h, Date = \"Date\",Close = \"Close\"):\n    w = Window.orderBy(Date)\n    df = df.withColumn('Lead{0}'.format(h), lead(Close, h).over(w))\n    df = df.withColumn('target_Date', lead(Date, h).over(w))\n    df = df.withColumn(\"diff{0}\".format(h), df['Lead{0}'.format(h)] -df[\"Close\"])\n    \n    return df\n  \ndef difference_maker(df, feature_name, h = 1):\n    w = Window.orderBy(\"Date\")\n    df = df.withColumn(\"Lag\", lag(feature_name,h).over(w))\n    df = df.withColumn(\"temp_name\", df[feature_name] -df[\"Lag\"]).drop(\"Lag\").drop(feature_name)\n    df = df.withColumnRenamed(\"temp_name\", feature_name)\n    \n    return df\n  \ndef difference_maker2(df, feature_name, h = 1):\n    w = Window.orderBy(\"Date\")\n    df = df.withColumn(\"Lag1\", lag(feature_name,1*h).over(w))\n    df = df.withColumn(\"Lag2\", lag(feature_name,2*h).over(w))\n    df = df.withColumn(\"temp_name\", df[\"Lag1\"] -df[\"Lag2\"]).drop(\"Lag1\").drop(\"Lag2\")\n    df = df.withColumnRenamed(\"temp_name\", feature_name+\"2\")\n    \n    return df\n\ndef feature_assembler(df, feature_list, output_name=\"features\"):\n    from pyspark.ml.feature import VectorAssembler\n    V_assem = VectorAssembler(inputCols = feature_list, outputCol = output_name)\n    df = V_assem.transform(df)\n    return df\n\ndef standard_scaler(df, input_name=\"features\", output_name=\"s_features\"):\n    from pyspark.ml.feature import StandardScaler\n    scaler = StandardScaler(inputCol=input_name, outputCol=output_name, withStd=True, withMean=False)\n    df = scaler.fit(df).transform(df)\n    return df\n\ndef pca(df, input_name=\"features\", output_name=\"pca_features\", keep = 10):\n    from pyspark.ml.feature import PCA\n    pca = PCA(k=keep, inputCol=input_name, outputCol=output_name)\n    df = pca.fit(df).transform(df)\n    return df\n\ndef df_col_selecter(df, col_list = [\"Date\",\"target_date\",\"Close\",\"pca_features\"]):\n    df = df.select([col for col in col_list])\n    return df\n  \n# 'pcaFeatures','Date','target_Date','Close','diff{0}'.format(h),'Lead{0}'.format(h)\n\ndef correlation_checker(df, feature_col):\n    from pyspark.ml.stat import Correlation\n    r1 = Correlation.corr(df, feature_col).head()\n    print(\"Pearson correlation matrix:\\n\" + str(r1[0]))\n\n\ndef data_split(df, train_size = 0.6 , val_size = 0.2, test_size = 0.2):\n    w = Window.orderBy(\"Date\")\n    df = df.withColumn('rank', percent_rank().over(w))\n    training = df.where('rank <= {0}'.format(train_size)).drop('rank')\n    val = df.where('rank > {0} AND rank <= {1}'.format(train_size, (train_size+val_size))).drop('rank')\n    test = df.where('rank > {0}'.format(1-test_size)).drop('rank')\n    return training, val, test\n\ndef random_forest(training, test, feature_list, features = \"features\", label = \"label\", h = 1, depth = 2, bins = 100, numtree = 100, print_result = False):\n    rf = RandomForestRegressor(featuresCol = features, labelCol = label, maxDepth = depth, maxBins = bins, numTrees = numtree, seed = 42)\n    model = rf.fit(training)\n    prediction = model.transform(test)\n    prediction = prediction.withColumn('pred', prediction['Close'] + prediction['prediction'])\n#     prediction = prediction.withColumnRenamed(\"prediction\",\"pred\")\n  \n    rmse_evaluator = RegressionEvaluator(labelCol=\"Lead{0}\".format(h), predictionCol=\"pred\", metricName=\"rmse\")\n    r2_evaluator = RegressionEvaluator(labelCol=\"Lead{0}\".format(h), predictionCol=\"pred\", metricName=\"r2\")\n    smape = sMAPE(prediction,\"pred\",\"Lead{0}\".format(h))\n    dsmape = sMAPE(prediction,\"Close\",\"Lead{0}\".format(h))\n#     csmape = sMAPE(prediction,\"Close\",\"pred\".format(h))\n    if print_result:\n        print(\"Random Forest to forecast {0} day into future:\".format(h))\n        print(\"RMSE is\", rmse_evaluator.evaluate(prediction))\n        print(\"r2 is\", r2_evaluator.evaluate(prediction))\n        print(\"sMAPE is: \", smape, \"default smape:\", dsmape)\n        importance_list = model.featureImportances\n        feature_importance = dict(zip(feature_list, importance_list))\n#         sorted_feature_importance = sorted(feature_importance, key=feature_importance.get, reverse=True)\n        sorted_feature_importance = sorted(feature_importance.items(), key=lambda x:x[1], reverse=True)\n        print(sorted_feature_importance)\n        \n    return smape, prediction\n  \ndef decision_tree(training, test, feature_list, features = \"features\", label = \"label\", h = 1, depth = 2, bins = 100, numtree = 100, print_result = False):\n  rf = DecisionTreeRegressor(featuresCol= features, labelCol= label, maxDepth = depth, maxBins = bins)\n  model = rf.fit(training)\n  prediction = model.transform(test)\n  prediction = prediction.withColumn('pred', prediction['Close'] + prediction['prediction'])\n#     prediction = prediction.withColumnRenamed(\"prediction\",\"pred\")\n\n  rmse_evaluator = RegressionEvaluator(labelCol=\"Lead{0}\".format(h), predictionCol=\"pred\", metricName=\"rmse\")\n  r2_evaluator = RegressionEvaluator(labelCol=\"Lead{0}\".format(h), predictionCol=\"pred\", metricName=\"r2\")\n  smape = sMAPE(prediction,\"pred\",\"Lead{0}\".format(h))\n  dsmape = sMAPE(prediction,\"Close\",\"Lead{0}\".format(h))\n#     csmape = sMAPE(prediction,\"Close\",\"pred\".format(h))\n  if print_result:\n      print(\"Random Forest to forecast {0} day into future:\".format(h))\n      print(\"RMSE is\", rmse_evaluator.evaluate(prediction))\n      print(\"r2 is\", r2_evaluator.evaluate(prediction))\n      print(\"sMAPE is: \", smape, \"default smape:\", dsmape)\n      importance_list = model.featureImportances\n      feature_importance = dict(zip(feature_list, importance_list))\n#         sorted_feature_importance = sorted(feature_importance, key=feature_importance.get, reverse=True)\n      sorted_feature_importance = sorted(feature_importance.items(), key=lambda x:x[1], reverse=True)\n      print(sorted_feature_importance)\n\n  return smape, prediction\n\ndef print_df(df,num = 10):\n    print(\"Date ascending:\")\n    df.show(num)\n    print(\"Date descending:\")\n    df.orderBy(desc(\"Date\")).show(num)\n    \ndef plot_graph(sdf, pred = 'pred', target = 'Lead84', target_Date = \"target_Date\"):\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    df = sdf.toPandas()\n    date = np.array(df[target_Date])\n    y = np.array(df[target])\n    pred_y = np.array(df[pred])\n    fig = plt.figure(figsize=(15, 5))\n    plt.plot(date, y ,marker='.',linestyle = '-',label = \"Actual Close Price\")\n    plt.plot(date, pred_y, marker='.',linestyle = '--',label = \"Predicted Close Price\")\n    plt.title('Close Price vs. Date for {0}'.format(target))\n    plt.xlabel('Date')\n    plt.ylabel('Price($)')\n    plt.legend()\n    display(fig.figure)\n    \ndef hyper_para_tester( h, training, val, feature_list, print_result = False):\n    last_smape = 100\n    for n in [2,3,4,5]:\n      depth = n\n      for m in [10,50,100,150,200]:\n        numtree = m\n        for b in [90,100,110]:\n          bins = b\n          smape , _ = random_forest(training, val, feature_list, \"s_features\", \"diff{0}\".format(h), h, depth, bins, numtree, print_result = False)\n          if smape < last_smape:\n            best_smape = smape\n            best_bins = bins\n            best_depth = depth\n            best_numtree = numtree\n            last_smape = smape\n    if print_result:\n      print(\"best_smape:\",best_smape,\"\\n\",\\\n            \"\\n\",\"best_bins:\",best_bins,\"\\n\",\"best_depth:\",best_depth,\"\\n\",\"best_numtree:\",best_numtree)\n    return best_bins, best_depth, best_numtree"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["h = 84\n\ndf = sqlContext.sql('SELECT * FROM all_feature').dropna()\n\ndf = target_creation(df, h, Date = \"Date\", Close = \"Close\")\ndf = df.withColumn(\"Close_lag\",df[\"Close\"])\n\nfeature_list = [\"Close_lag\",\"sp500\",\"nasdaq100\",\"DoeJonesIA\",\"USDtoCNY\",\"USDtoEUR\",\"USDtoJPY\",\"AnalogDevice\",\"Jabil\",\"Microsoft\",\"Nidec\",\"Qualcomm\",\"TSMC\",\"CPI\",\"USA MSCI\",\"will5000\"]\n\nfor feature in feature_list:\n  df = difference_maker(df, feature_name = feature, h = h)\n\n\ndf = df.dropna()\ndf = feature_assembler(df, feature_list, output_name=\"features\")\n\ndf = standard_scaler(df, input_name=\"features\", output_name=\"s_features\")\n# df = pca(df, input_name=\"s_features\", output_name=\"pca_features\", keep = 10)\n\n\ncol_list = [\"Date\",\"Close\",\"s_features\",\"diff{0}\".format(h),\"target_date\",\"Lead{0}\".format(h)]\ndf = df_col_selecter(df, col_list)\n\n\n# correlation_checker(df, \"s_features\")\n\ntraining, val, test = data_split(df, train_size = 0.6 , val_size = 0.2, test_size = 0.2)\n\n# best_bins, best_depth, best_numtree = hyper_para_tester( h, training, val, feature_list, print_result = True)\n\nbest_bins = 110 \nbest_depth = 2 \nbest_numtree = 10"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["training, val, test = data_split(df, train_size = 0.6 , val_size = 0.2, test_size = 0.2)\nsmape84, pred84 = decision_tree(training, test, feature_list, features = \"s_features\", label = \"diff{0}\".format(h), h = h , depth = best_depth, bins = best_bins, numtree = best_numtree, print_result = True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Random Forest to forecast 84 day into future:\nRMSE is 19.096901066601816\nr2 is 0.3332513246373966\nsMAPE is:  8.751507603859375 default smape: 11.758825151401322\n[(&#39;sp500&#39;, 0.4799629722927624), (&#39;Nidec&#39;, 0.3959960973511156), (&#39;USA MSCI&#39;, 0.12404093035612189), (&#39;Close_lag&#39;, 0.0), (&#39;nasdaq100&#39;, 0.0), (&#39;DoeJonesIA&#39;, 0.0), (&#39;USDtoCNY&#39;, 0.0), (&#39;USDtoEUR&#39;, 0.0), (&#39;USDtoJPY&#39;, 0.0), (&#39;AnalogDevice&#39;, 0.0), (&#39;Jabil&#39;, 0.0), (&#39;Microsoft&#39;, 0.0), (&#39;Qualcomm&#39;, 0.0), (&#39;TSMC&#39;, 0.0), (&#39;CPI&#39;, 0.0), (&#39;will5000&#39;, 0.0)]\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["plot_graph(pred84, pred = 'pred', target = 'Lead{0}'.format(h), target_Date = \"target_date\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["training, val, test = data_split(df, train_size = 0.6 , val_size = 0.2, test_size = 0.2)\nsmape84, pred84 = random_forest(training, test, feature_list, features = \"s_features\", label = \"diff{0}\".format(h), h = h , depth = best_depth, bins = best_bins, numtree = best_numtree, print_result = True)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Random Forest to forecast 84 day into future:\nRMSE is 20.840662819163107\nr2 is 0.2059288464607093\nsMAPE is:  9.406598249299684 default smape: 11.758825151401322\n[(&#39;USDtoEUR&#39;, 0.27311886027552684), (&#39;Nidec&#39;, 0.17026710372877768), (&#39;Close_lag&#39;, 0.1431244753949517), (&#39;USA MSCI&#39;, 0.1320373280733095), (&#39;will5000&#39;, 0.07846886517538658), (&#39;TSMC&#39;, 0.05450011375873452), (&#39;sp500&#39;, 0.053433921288010625), (&#39;USDtoJPY&#39;, 0.0359778244926988), (&#39;Jabil&#39;, 0.024855308583388993), (&#39;USDtoCNY&#39;, 0.012839693562573615), (&#39;AnalogDevice&#39;, 0.010972160496689472), (&#39;CPI&#39;, 0.010404345169951684), (&#39;nasdaq100&#39;, 0.0), (&#39;DoeJonesIA&#39;, 0.0), (&#39;Microsoft&#39;, 0.0), (&#39;Qualcomm&#39;, 0.0)]\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["plot_graph(pred84, pred = 'pred', target = 'Lead{0}'.format(h), target_Date = \"target_date\")"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["h = 21\n\ndf = sqlContext.sql('SELECT * FROM all_feature').dropna()\n\ndf = target_creation(df, h, Date = \"Date\", Close = \"Close\")\ndf = df.withColumn(\"Close_lag\",df[\"Close\"])\n\nfeature_list = [\"Close_lag\",\"sp500\",\"nasdaq100\",\"DoeJonesIA\",\"USDtoCNY\",\"USDtoEUR\",\"USDtoJPY\",\"AnalogDevice\",\"Jabil\",\"Microsoft\",\"Nidec\",\"Qualcomm\",\"TSMC\",\"CPI\",\"USA MSCI\",\"will5000\"]\n\nfor feature in feature_list:\n  df = difference_maker(df, feature_name = feature, h = h)\n\n\ndf = df.dropna()\ndf = feature_assembler(df, feature_list, output_name=\"features\")\n\ndf = standard_scaler(df, input_name=\"features\", output_name=\"s_features\")\n# df = pca(df, input_name=\"s_features\", output_name=\"pca_features\", keep = 10)\n\n\ncol_list = [\"Date\",\"Close\",\"s_features\",\"diff{0}\".format(h),\"target_date\",\"Lead{0}\".format(h)]\ndf = df_col_selecter(df, col_list)\n\n\n# correlation_checker(df, \"s_features\")\n\ntraining, val, test = data_split(df, train_size = 0.6 , val_size = 0.2, test_size = 0.2)\n\n# best_bins, best_depth, best_numtree = hyper_para_tester( h, training, val, feature_list, print_result = True)\nbest_bins = 90 \nbest_depth = 5 \nbest_numtree = 150\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["smape21, pred21 = decision_tree(training, val, feature_list, features = \"s_features\", label = \"diff{0}\".format(h), h = h , depth = best_depth, bins = best_bins, numtree = best_numtree, print_result = True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Random Forest to forecast 21 day into future:\nRMSE is 9.158385466619984\nr2 is 0.29023430617570767\nsMAPE is:  6.43629265865892 default smape: 5.501173337159433\n[(&#39;AnalogDevice&#39;, 0.21948348432313405), (&#39;Jabil&#39;, 0.17353294532521535), (&#39;CPI&#39;, 0.15167331598628866), (&#39;USA MSCI&#39;, 0.10784998166729183), (&#39;Nidec&#39;, 0.08718019297214666), (&#39;USDtoCNY&#39;, 0.08554434618355002), (&#39;TSMC&#39;, 0.07486645659851364), (&#39;USDtoEUR&#39;, 0.055780592342918225), (&#39;Close_lag&#39;, 0.014715948534654872), (&#39;sp500&#39;, 0.013818272024492678), (&#39;Qualcomm&#39;, 0.012507074169019463), (&#39;nasdaq100&#39;, 0.0024736428865242987), (&#39;USDtoJPY&#39;, 0.0005737469862502276), (&#39;DoeJonesIA&#39;, 0.0), (&#39;Microsoft&#39;, 0.0), (&#39;will5000&#39;, 0.0)]\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["plot_graph(pred21, pred = 'pred', target = 'Lead{0}'.format(h), target_Date = \"target_date\")"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["smape21, pred21 = random_forest(training, val, feature_list, features = \"s_features\", label = \"diff{0}\".format(h), h = h , depth = best_depth, bins = best_bins, numtree = best_numtree, print_result = True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Random Forest to forecast 21 day into future:\nRMSE is 7.791527328153624\nr2 is 0.4862848620852722\nsMAPE is:  5.489001092276717 default smape: 5.501173337159433\n[(&#39;CPI&#39;, 0.13213270828193865), (&#39;AnalogDevice&#39;, 0.12281601929079872), (&#39;USA MSCI&#39;, 0.11574338673141289), (&#39;Jabil&#39;, 0.11063819682565017), (&#39;USDtoCNY&#39;, 0.09163444769011019), (&#39;USDtoJPY&#39;, 0.06603784073202346), (&#39;USDtoEUR&#39;, 0.06257313438858492), (&#39;TSMC&#39;, 0.04752448862945104), (&#39;Microsoft&#39;, 0.045947584519198184), (&#39;Nidec&#39;, 0.04567167242501253), (&#39;Close_lag&#39;, 0.04500925776808068), (&#39;nasdaq100&#39;, 0.03184091073046842), (&#39;Qualcomm&#39;, 0.02461411854574196), (&#39;will5000&#39;, 0.021805683681847137), (&#39;sp500&#39;, 0.020539786362301568), (&#39;DoeJonesIA&#39;, 0.015470763397379432)]\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["plot_graph(pred21, pred = 'pred', target = 'Lead{0}'.format(h), target_Date = \"target_date\")"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["h = 10\n\ndf = sqlContext.sql('SELECT * FROM all_feature').dropna()\n\ndf = target_creation(df, h, Date = \"Date\", Close = \"Close\")\ndf = df.withColumn(\"Close_lag\",df[\"Close\"])\n\nfeature_list = [\"Close_lag\",\"sp500\",\"nasdaq100\",\"DoeJonesIA\",\"USDtoCNY\",\"USDtoEUR\",\"USDtoJPY\",\"AnalogDevice\",\"Jabil\",\"Microsoft\",\"Nidec\",\"Qualcomm\",\"TSMC\",\"CPI\",\"USA MSCI\",\"will5000\"]\n\nfor feature in feature_list:\n  df = difference_maker(df, feature_name = feature, h = h)\n\n\ndf = df.dropna()\ndf = feature_assembler(df, feature_list, output_name=\"features\")\n\ndf = standard_scaler(df, input_name=\"features\", output_name=\"s_features\")\n# df = pca(df, input_name=\"s_features\", output_name=\"pca_features\", keep = 10)\n\n\ncol_list = [\"Date\",\"Close\",\"s_features\",\"diff{0}\".format(h),\"target_date\",\"Lead{0}\".format(h)]\ndf = df_col_selecter(df, col_list)\n\n\n# correlation_checker(df, \"s_features\")\n\ntraining, val, test = data_split(df, train_size = 0.6 , val_size = 0.2, test_size = 0.2)\n\n# best_bins, best_depth, best_numtree = hyper_para_tester( h, training, val, feature_list, print_result = True)\nbest_bins = 90 \nbest_depth = 3 \nbest_numtree = 10"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["smape10, pred10 = decision_tree(training, val, feature_list, features = \"s_features\", label = \"diff{0}\".format(h), h = h , depth = best_depth, bins = best_bins, numtree = best_numtree, print_result = True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Random Forest to forecast 10 day into future:\nRMSE is 5.478186000311595\nr2 is 0.7421564031406358\nsMAPE is:  3.872551468522793 default smape: 3.660763480118039\n[(&#39;Microsoft&#39;, 0.3184269811875784), (&#39;USA MSCI&#39;, 0.23138114037371454), (&#39;nasdaq100&#39;, 0.2183034412382364), (&#39;TSMC&#39;, 0.150891019583368), (&#39;USDtoCNY&#39;, 0.04650845859907456), (&#39;Close_lag&#39;, 0.03448895901802816), (&#39;sp500&#39;, 0.0), (&#39;DoeJonesIA&#39;, 0.0), (&#39;USDtoEUR&#39;, 0.0), (&#39;USDtoJPY&#39;, 0.0), (&#39;AnalogDevice&#39;, 0.0), (&#39;Jabil&#39;, 0.0), (&#39;Nidec&#39;, 0.0), (&#39;Qualcomm&#39;, 0.0), (&#39;CPI&#39;, 0.0), (&#39;will5000&#39;, 0.0)]\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["plot_graph(pred10, pred = 'pred', target = 'Lead{0}'.format(h), target_Date = \"target_date\")"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["smape10, pred10 = random_forest(training, val, feature_list, features = \"s_features\", label = \"diff{0}\".format(h), h = h , depth = best_depth, bins = best_bins, numtree = best_numtree, print_result = True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Random Forest to forecast 10 day into future:\nRMSE is 5.060321442923288\nr2 is 0.7799917261970828\nsMAPE is:  3.582827190381139 default smape: 3.660763480118039\n[(&#39;USA MSCI&#39;, 0.22441793697116066), (&#39;Microsoft&#39;, 0.2069507608264718), (&#39;nasdaq100&#39;, 0.15293606535543394), (&#39;Jabil&#39;, 0.07453958680404146), (&#39;TSMC&#39;, 0.06728505059429958), (&#39;will5000&#39;, 0.05563137039190785), (&#39;Qualcomm&#39;, 0.04923807857729948), (&#39;Nidec&#39;, 0.03483877869192452), (&#39;CPI&#39;, 0.03481896191015901), (&#39;AnalogDevice&#39;, 0.027075755821885455), (&#39;DoeJonesIA&#39;, 0.019946023662707524), (&#39;USDtoJPY&#39;, 0.019022347119266526), (&#39;USDtoCNY&#39;, 0.01602260356597151), (&#39;USDtoEUR&#39;, 0.015583005068893496), (&#39;sp500&#39;, 0.0014192028981403855), (&#39;Close_lag&#39;, 0.00027447174043661895)]\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["plot_graph(pred10, pred = 'pred', target = 'Lead{0}'.format(h), target_Date = \"target_date\")"],"metadata":{},"outputs":[],"execution_count":16}],"metadata":{"kernelspec":{"display_name":"Python 3 + Pyspark","language":"python","name":"pyspark3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.8","nbconvert_exporter":"python","file_extension":".py"},"name":"Random Forest","notebookId":4144215612452542},"nbformat":4,"nbformat_minor":0}
